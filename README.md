# deeplabv3-vslam
Dynamic Scene Semantic Visual SLAM based on Deep Learning

In this project, we propose a method to improve the robustness and accuracy of monocular visual odometry in dynamic environments. The method uses the semantic segmentation algorithm DeeplabV3+ to identify dynamic objects in the image, and then applies a motion consistency check to further remove the feature points belonging to dynamic objects. The remaining static feature points are then used for feature matching and pose estimation based on ORB-SLAM2. By eliminating the influence of dynamic objects, our method improves the accuracy and robustness of visual odometry in dynamic environments. Experimental results show that our proposed method outperforms traditional visual odometry methods in terms of accuracy and robustness, especially in dynamic environments. Experiments of the system were conducted using an open dataset from the Technical University of Munich (TUM). The results show that, compared to the traditional ORB-SLAM2, the system significantly reduces the absolute trajectory error and the relative pose error in dynamic scenes, and significantly improves the accuracy and robustness of the SLAM system's pose estimation.
